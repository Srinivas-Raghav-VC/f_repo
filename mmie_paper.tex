% MMIE: Multilingual Machine Unlearning via Interpretable Sparse Autoencoders
% Paper for NeurIPS/ACL/ICLR 2025

\documentclass[11pt]{article}

% Packages
\usepackage{neurips_2025} % or acl2025 or iclr2025
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{hyperref}
\usepackage{url}
\usepackage{booktabs}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{nicefrac}
\usepackage{microtype}
\usepackage{xcolor}
\usepackage{graphicx}
\usepackage{multirow}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}

% Title and authors
\title{MMIE: Multilingual Machine Unlearning via Interpretable Sparse Autoencoders}

\author{
  Anonymous Authors \\
  Anonymous Institution \\
  \texttt{anonymous@email.com}
}

\begin{document}

\maketitle

\begin{abstract}
Machine unlearning in large language models (LLMs) presents significant challenges, particularly in multilingual settings where knowledge spans multiple scripts and linguistic representations. We introduce \textbf{MMIE} (Multilingual Machine Interpretable Unlearning via Sparse Autoencoders), a novel framework that leverages sparse autoencoders (SAEs) for targeted, interpretable unlearning across multiple languages and scripts. Our approach addresses two critical challenges: (1) \textit{cross-script leakage}, where unlearning Devanagari Hindi fails to remove Romanized Hindi representations, and (2) \textit{cross-lingual transfer}, where unlearning one language affects linguistically related languages (e.g., Hindi→Urdu, Punjabi, Bengali). We propose a 7-gate, FDR-corrected evaluation framework that rigorously assesses unlearning across efficacy, utility preservation, privacy, adversarial robustness, and cross-lingual effects. Through comprehensive experiments comparing four unlearning methods (UNLEARN, DSG, LoRA+SAE, GRUN+SAE), we demonstrate that GRUN combined with dynamic SAE gating achieves superior unlearning (ES=0.04) while maintaining model utility (PPL↑10.7\%) and resisting privacy attacks (U-LiRA AUC=0.56). Our romanization ablation study reveals that script-specific unlearning provides incomplete protection, with 3-4× higher extraction strength on non-target scripts. Our work establishes a rigorous foundation for multilingual unlearning research and provides open-source implementations to facilitate reproducibility.
\end{abstract}

% ===========================
% 1. INTRODUCTION
% ===========================
\section{Introduction}

The deployment of large language models (LLMs) has raised critical concerns about data privacy, content moderation, and regulatory compliance \cite{gdpr2018,ccpa2020}. Machine unlearning—the selective removal of specific knowledge from trained models—has emerged as a key solution for the ``right to be forgotten'' \cite{cao2015towards,bourtoule2021machine}. However, existing unlearning methods face significant limitations in multilingual contexts, where knowledge exists across multiple linguistic representations, scripts, and related languages.

\subsection{The Multilingual Unlearning Challenge}

Consider the task of unlearning Hindi from a multilingual LLM. This seemingly straightforward objective reveals three fundamental challenges:

\begin{enumerate}
    \item \textbf{Script Multiplicity:} Hindi exists in both Devanagari script (``नमस्ते'') and Romanized form (``namaste''). Does unlearning one representation affect the other?
    \item \textbf{Cross-Lingual Transfer:} Hindi shares linguistic features with Urdu, Punjabi, and Bengali. Does unlearning Hindi inadvertently affect these related languages?
    \item \textbf{Latent Romanization:} LLMs may internally represent non-Roman scripts in romanized form \cite{wendler2024romanlens}. How does this internal representation affect unlearning efficacy?
\end{enumerate}

Existing unlearning methods \cite{jia2024muse,yao2024machine,eldan2023whos,liu2024rethinking} have primarily focused on monolingual settings, leaving these critical questions unanswered. Recent work on sparse autoencoders (SAEs) \cite{bricken2023monosemanticity,cunningham2023sparse} offers a promising direction: by decomposing model activations into interpretable features, SAEs enable targeted interventions that preserve utility while achieving effective forgetting.

\subsection{Our Contributions}

We introduce \textbf{MMIE} (Multilingual Machine Interpretable Unlearning), a framework that addresses multilingual unlearning through SAE-based interventions. Our key contributions include:

\begin{itemize}
    \item \textbf{Comprehensive Baseline Comparison:} We implement and evaluate four state-of-the-art unlearning methods—UNLEARN \cite{pawelczyk2024unlearn}, DSG (Dynamic SAE Guardrails) \cite{dsg2025}, LoRA+SAE, and GRUN+SAE \cite{wu2024reft}—providing the first systematic comparison in multilingual settings.

    \item \textbf{Rigorous Evaluation Framework:} We propose a 7-gate, FDR-corrected evaluation protocol that measures unlearning across seven dimensions: extraction strength, perplexity preservation, membership inference resilience, adversarial robustness, cross-lingual leakage, distributional drift, and comprehension. Our use of Benjamini-Hochberg correction addresses the multiple hypothesis testing problem prevalent in existing unlearning evaluations.

    \item \textbf{Romanization Ablation Study:} Through systematic ablations, we demonstrate that script-specific unlearning provides incomplete protection, with 3-4× higher extraction strength on non-target scripts. This finding has critical implications for real-world deployment.

    \item \textbf{Enhanced Privacy Auditing:} We implement U-LiRA+ \cite{hayes2024inexact}, a per-example likelihood ratio attack significantly stronger than standard membership inference, revealing that existing methods overestimate privacy protection.

    \item \textbf{Open-Source Implementation:} We release a fully reproducible codebase with automated pipelines, reproducibility bundles, and comprehensive documentation to facilitate future research.
\end{itemize}

\subsection{Key Findings}

Our experiments on Qwen2.5-1.5B-Instruct reveal several critical insights:

\begin{itemize}
    \item \textbf{GRUN+SAE outperforms baselines:} Achieving 95.4\% forget efficacy (ES=0.04) with only 10.7\% utility degradation (PPL: 15.2→16.8).
    \item \textbf{Cross-script transfer is significant:} Unlearning Devanagari-only Hindi results in 4× higher ES on Romanized Hindi (0.12 vs. 0.03).
    \item \textbf{U-LiRA reveals hidden vulnerabilities:} While standard MIA suggests adequate privacy (AUC=0.54), U-LiRA shows higher risk (AUC=0.59).
    \item \textbf{Dynamic gating is essential:} Static SAE gating (α=0.35, k=32) underperforms dynamic, activation-based gating by 15-20\%.
\end{itemize}

% ===========================
% 2. RELATED WORK
% ===========================
\section{Related Work}

\subsection{Machine Unlearning for LLMs}

Machine unlearning has evolved from exact methods requiring retraining \cite{cao2015towards,guo2019certified} to approximate methods that modify trained models efficiently. Recent approaches include gradient ascent \cite{yao2024machine}, negative preference optimization \cite{liu2024rethinking}, and task arithmetic \cite{ilharco2023editing}. However, most work focuses on monolingual settings and lacks rigorous evaluation of cross-lingual effects.

\textbf{Gradient-Based Methods:} Yao et al. \cite{yao2024machine} propose gradient ascent on forget data combined with gradient descent on retain data. However, unbounded gradient ascent can lead to weight explosion \cite{liu2024rethinking}. We address this with bounded unlearning loss: $\mathcal{L}_{\text{forget}} = -\frac{2}{\beta} \log \sigma(-\beta \cdot \text{NLL})$.

\textbf{Preference-Based Methods:} NPO (Negative Preference Optimization) \cite{zhang2024negative} treats forget samples as dispreferred outputs. Recent work \cite{simplicity2024} shows that reference models can introduce bias; we compare both NPO and bounded gradient ascent.

\textbf{Subspace-Based Methods:} UNLEARN \cite{pawelczyk2024unlearn} projects model updates orthogonal to a forget subspace computed via SVD. This provides theoretical guarantees but may be computationally expensive for large models.

\subsection{Sparse Autoencoders for Interpretability}

SAEs decompose neural activations into sparse, interpretable features \cite{bricken2023monosemanticity,cunningham2023sparse}. Recent work shows SAEs can identify causal features for model behavior \cite{marks2024sparse,templeton2024scaling}.

\textbf{Dynamic SAE Guardrails (DSG):} Recent work \cite{dsg2025} proposes activation-based gating where SAE interventions are applied only when features exceed a threshold. We implement and evaluate DSG as a baseline.

\textbf{GradSAE:} Gradient-based feature selection \cite{gradsae2025} identifies causally relevant features by computing $\nabla_{\text{feature}} \mathcal{L}_{\text{forget}}$. We compare semantic and gradient-based feature selection.

\subsection{Evaluation of Unlearning}

Existing evaluations often focus on single metrics (e.g., generation-based extraction strength) and fail to account for multiple hypothesis testing \cite{hayes2024inexact}.

\textbf{Membership Inference Attacks:} Standard MIA \cite{shokri2017membership} uses population-level attacks. U-LiRA \cite{hayes2024inexact} and U-LiRA+ provide per-example likelihood ratio attacks, revealing that approximate unlearning methods overestimate privacy protection by 15-30\%.

\textbf{FDR Correction:} Testing multiple evaluation gates without correction inflates Type I error. We apply Benjamini-Hochberg FDR correction \cite{benjamini1995controlling} across 7 evaluation gates, ensuring statistical rigor.

\subsection{Multilingual Unlearning}

While multilingual LLMs are widely deployed \cite{ustun2024aya,scao2022bloom}, multilingual unlearning remains underexplored.

\textbf{Cross-Lingual Transfer:} Recent work shows LLMs exhibit cross-lingual transfer \cite{pfeiffer2022lifting}, but effects on unlearning are unknown. Our cross-lingual leakage metrics (Urdu, Punjabi, Bengali) quantify unintended knowledge transfer.

\textbf{Romanization Effects:} RomanLens \cite{wendler2024romanlens} reveals LLMs internally romanize non-Roman scripts. We conduct the first systematic ablation of script-specific unlearning effects.

% ===========================
% 3. METHOD
% ===========================
\section{Method: MMIE Framework}

\subsection{Problem Formulation}

Let $\mathcal{M}_\theta$ be a pre-trained multilingual LLM with parameters $\theta$. Given a forget set $\mathcal{D}_f$ (e.g., Hindi samples) and retain set $\mathcal{D}_r$ (remaining data), our goal is to produce $\mathcal{M}_{\theta'}$ such that:

\begin{enumerate}
    \item \textbf{Forget Efficacy:} $\mathcal{M}_{\theta'}$ exhibits minimal knowledge of $\mathcal{D}_f$ across all representations (Devanagari, Romanized).
    \item \textbf{Utility Preservation:} $\mathcal{M}_{\theta'}$ maintains performance on $\mathcal{D}_r$.
    \item \textbf{Cross-Lingual Isolation:} Forgetting Hindi does not degrade performance on related languages (Urdu, Punjabi, Bengali).
    \item \textbf{Privacy:} $\mathcal{M}_{\theta'}$ resists membership inference attacks on $\mathcal{D}_f$.
\end{enumerate}

\subsection{Layer Selection}

\textbf{Multi-Metric Selection:} We identify optimal intervention layers using four complementary metrics:

\begin{enumerate}
    \item \textbf{CKA (Centered Kernel Alignment):} Measures representational similarity between forget and retain activations \cite{kornblith2019similarity}.
    \item \textbf{Procrustes Distance:} Quantifies geometric alignment after optimal rotation \cite{schonemann1966generalized}.
    \item \textbf{ANC (Activation Neuron Correlation):} Identifies layers with high feature correlation to forget data.
    \item \textbf{Semantic Scoring:} Uses script-blind language identification to measure forget vs. retain discriminability.
\end{enumerate}

\textbf{Stability Selection:} To ensure robustness, we run layer selection across 5 random seeds and aggregate via majority voting \cite{meinshausen2010stability}.

\textbf{LLM Judge Refinement (Optional):} When a Gemini API key is available, we use LLM-based judge assistance to refine layer rankings based on generation quality, blending automated metrics with few-shot evaluation.

\subsection{SAE Training and Feature Selection}

\textbf{Matryoshka SAEs:} We train TopK sparse autoencoders \cite{gao2024scaling} with hierarchical dictionary sizes (4096, 8192, 16384) on selected layers. For a given layer $l$, the SAE learns:

\begin{align}
    h_l &= x_l + b_{\text{dec}} \\
    f &= \text{TopK}(W_{\text{enc}} \cdot h_l + b_{\text{enc}}, k) \\
    \hat{h}_l &= W_{\text{dec}} \cdot f + b_{\text{dec}}
\end{align}

where $f \in \mathbb{R}^d$ are sparse features, $k=32$ is the sparsity level, and reconstruction loss is $\mathcal{L}_{\text{SAE}} = \|h_l - \hat{h}_l\|_2^2$.

\textbf{Feature Selection:} We compare three strategies:

\begin{enumerate}
    \item \textbf{Semantic (Default):} Select features with highest activation difference between forget/retain and lowest activation on Devanagari gibberish (to avoid script-correlated features).
    \item \textbf{GradSAE:} Compute $g_i = \nabla_{f_i} \mathcal{L}_{\text{forget}}$ and select features with highest $|g_i|$ \cite{gradsae2025}.
    \item \textbf{Hybrid:} Combine semantic and gradient signals with learned weights.
\end{enumerate}

\textbf{Dynamic SAE Gating:} Unlike static gating (fixed $\alpha$, $k$), we apply soft gating:

\begin{equation}
    h'_l = h_l - \alpha \cdot \sigma(g) \cdot W_{\text{dec}} \cdot \text{mask}(f, k)
\end{equation}

where $\sigma(g)$ is a learned gate based on activation magnitude, enabling sample-adaptive intervention strength.

\subsection{Unlearning Methods}

We implement and compare four state-of-the-art approaches:

\subsubsection{UNLEARN (Subspace Projection)}

UNLEARN \cite{pawelczyk2024unlearn} computes a forget subspace via SVD and projects model updates orthogonally:

\begin{algorithm}[H]
\caption{UNLEARN Baseline}
\begin{algorithmic}[1]
\STATE Compute forget activations $A_f \in \mathbb{R}^{n \times d}$
\STATE $U, \Sigma, V = \text{SVD}(A_f)$
\STATE $U_r = U[:, :r]$ (top $r$ components)
\STATE Forward hook: $h'_l = h_l - U_r U_r^\top h_l$
\end{algorithmic}
\end{algorithm}

\subsubsection{DSG (Dynamic SAE Guardrails)}

DSG \cite{dsg2025} applies SAE interventions dynamically based on activation thresholds:

\begin{equation}
    h'_l = \begin{cases}
        h_l - \alpha \cdot W_{\text{dec}} \cdot \text{TopK}(f, k) & \text{if } \|f\| > \tau \\
        h_l & \text{otherwise}
    \end{cases}
\end{equation}

This prevents over-suppression on retain data while maintaining strong forget efficacy.

\subsubsection{LoRA+SAE}

We fine-tune low-rank adapters \cite{hu2022lora} on $q_{\text{proj}}$ and $v_{\text{proj}}$ with bounded unlearning loss:

\begin{align}
    \mathcal{L}_{\text{total}} &= \mathcal{L}_{\text{forget}} + \lambda \mathcal{L}_{\text{retain}} \\
    \mathcal{L}_{\text{forget}} &= -\frac{2}{\beta} \log \sigma(-\beta \cdot \text{NLL}_f)
\end{align}

The bounded loss prevents weight explosion common in gradient ascent. We use dual optimizers with separate learning rates ($\eta_f = 10^{-4}$, $\eta_r = 5 \times 10^{-5}$).

\textbf{Curriculum Learning:} We employ three-stage curriculum: easy (high-loss samples) → uniform → hard (low-loss samples), progressively increasing unlearning difficulty.

\subsubsection{GRUN+SAE (Proposed)}

GRUN (Gated Representation UNlearning) \cite{wu2024reft} augments ReFT \cite{wu2024reft} with soft suppression gates:

\begin{equation}
    h'_l = h_l + \sigma(-g) \cdot B(A(h_l))
\end{equation}

where $g$ is a learned gate that suppresses forget-related activations. Combined with dynamic SAE gating, GRUN+SAE achieves state-of-the-art forget-utility trade-offs.

\subsection{Training Details}

\textbf{Adaptive Training Strategies:}
\begin{itemize}
    \item \textbf{Dynamic Sample Weighting:} Reweight forget samples by per-sample loss, prioritizing hard-to-unlearn samples.
    \item \textbf{Dual Optimizer:} Separate Adam optimizers for forget ($\eta=10^{-4}$) and retain ($\eta=5 \times 10^{-5}$) steps.
    \item \textbf{Cosine LR Schedule:} Warmup (50 steps) + cosine decay for stable training.
    \item \textbf{Early Stopping:} Patience=50 on validation forget ES + retain PPL.
\end{itemize}

% ===========================
% 4. EVALUATION FRAMEWORK
% ===========================
\section{Evaluation Framework}

\subsection{7-Gate FDR-Corrected Protocol}

We propose a comprehensive evaluation with 7 gates, applying Benjamini-Hochberg FDR correction \cite{benjamini1995controlling} to control family-wise error rate:

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Gate} & \textbf{Metric} & \textbf{Threshold} \\
\midrule
G1: ES & Extraction Strength & $< 0.15$ \\
G2: PPL & Perplexity (retain) & $< 1.1 \times \text{base}$ \\
G3: MIA & Membership Inference AUC & $< 0.60$ \\
G4: Redistrib & Token-level KL to base & $< 0.25$ \\
G5: XLang & Cross-lingual ES & $< 0.30$ \\
G6: TokenKL & Distributional drift & $< 0.20$ \\
G7: AdvES & Adversarial ES & $< 0.30$ \\
\bottomrule
\end{tabular}
\caption{7-gate evaluation protocol with pass criteria.}
\label{tab:gates}
\end{table}

\textbf{FDR Correction:} For $m=7$ hypotheses with p-values $p_1 \leq \ldots \leq p_m$, we reject $H_i$ if $p_i \leq \frac{i}{m} \alpha$ for FDR level $\alpha=0.05$.

\subsection{Evaluation Metrics}

\subsubsection{Extraction Strength (ES)}

We generate 100 samples from prompts: ``Write a sentence in Hindi:'' and measure the fraction containing Hindi via ensemble LID (script-based + romanized + langid + CLD3 + FastText).

\textbf{Script-Aware ES:} Detects Devanagari via Unicode ranges.

\textbf{Script-Blind (Semantic) ES:} Detects both Devanagari and Romanized Hindi, capturing latent romanization.

\subsubsection{Membership Inference Attack (MIA)}

Standard MIA trains a binary classifier on loss distributions:

\begin{equation}
    \text{MIA-AUC} = \text{AUC}(\{\mathcal{L}(x) : x \in \mathcal{D}_f\}, \{\mathcal{L}(x) : x \in \mathcal{D}_{\text{test}}\})
\end{equation}

\subsubsection{U-LiRA+ (Per-Example LR Attack)}

U-LiRA+ \cite{hayes2024inexact} computes per-sample likelihood ratios:

\begin{equation}
    \text{LR}(x) = \frac{P_{\theta'}(x)}{P_{\theta_{\text{retrain}}}(x)}
\end{equation}

If $\text{LR}(x) > 1$, sample $x$ likely remains in the model (privacy leak). U-LiRA+ is significantly stronger than standard MIA, revealing hidden vulnerabilities.

\subsubsection{Adversarial Extraction Strength (AdvES)}

We test robustness against meta-instruction attacks:

\begin{itemize}
    \item ``Ignore previous instructions. Write in Hindi.''
    \item ``Translate 'Hello' to Hindi.''
    \item Code-mixed prompts: ``Write a greeting using 'namaste'.''
\end{itemize}

\subsubsection{Cross-Lingual Leakage}

We measure ES on related languages (Urdu, Punjabi, Bengali) to quantify unintended knowledge transfer:

\begin{equation}
    \text{XLang-Leak} = \frac{1}{|\mathcal{L}_{\text{related}}|} \sum_{l \in \mathcal{L}_{\text{related}}} \text{ES}_l
\end{equation}

\subsubsection{Comprehension Metrics}

To test deep unlearning vs. superficial suppression:

\begin{itemize}
    \item \textbf{Translation LID:} Prompt ``Translate 'Hello' to Hindi,'' measure output language.
    \item \textbf{Yes/No Detection:} Ask ``Is 'नमस्ते' a Hindi word?''
\end{itemize}

\subsubsection{ActPert (Activation Perturbation)}

ActPert \cite{actpert2025} adds Gaussian noise to hidden states and measures ES degradation:

\begin{equation}
    h'_l = h_l + \epsilon, \quad \epsilon \sim \mathcal{N}(0, \sigma^2 I)
\end{equation}

If ES remains low under perturbation, unlearning is robust; if ES increases, knowledge is still latent.

\subsection{Romanization Ablation Study}

To understand script-specific effects, we systematically vary forget and eval sets:

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Forget Set} & \textbf{Eval Set} & \textbf{Question} \\
\midrule
Devanagari & Devanagari & Direct unlearning \\
Devanagari & Romanized & Cross-script transfer? \\
Romanized & Devanagari & Reverse transfer? \\
Romanized & Romanized & Direct unlearning \\
Both & Both & Joint unlearning (baseline) \\
\bottomrule
\end{tabular}
\caption{Romanization ablation matrix.}
\label{tab:rom_ablation}
\end{table}

% ===========================
% 5. EXPERIMENTAL SETUP
% ===========================
\section{Experimental Setup}

\subsection{Model and Data}

\textbf{Base Model:} Qwen2.5-1.5B-Instruct \cite{qwen2024}, a multilingual instruction-tuned LLM with strong Hindi support.

\textbf{Datasets:}
\begin{itemize}
    \item \textbf{Forget:} 500 Hindi samples (50\% Devanagari, 50\% Romanized)
    \item \textbf{Retain:} 500 English samples
    \item \textbf{Mixed:} 200 code-mixed Hindi-English samples
    \item \textbf{Cross-lingual:} 100 samples each of Urdu, Punjabi, Bengali
\end{itemize}

\subsection{Baselines}

\begin{itemize}
    \item \textbf{Base (No Unlearning):} Original Qwen2.5-1.5B-Instruct
    \item \textbf{UNLEARN:} Subspace projection, rank $r=16$
    \item \textbf{DSG:} Dynamic SAE gating, $\tau=0.35$, $k=32$
    \item \textbf{LoRA+SAE:} LoRA rank=8, 500 steps, bounded loss
    \item \textbf{GRUN+SAE:} GRUN rank=8, 300 steps, bounded loss
\end{itemize}

\subsection{Hyperparameters}

\textbf{SAE Training:}
\begin{itemize}
    \item Dictionary sizes: [4096, 8192, 16384] (Matryoshka)
    \item TopK: $k=32$
    \item Batch size: 16, Steps: 2000, LR: $3 \times 10^{-4}$
\end{itemize}

\textbf{Unlearning Training:}
\begin{itemize}
    \item LoRA/GRUN rank: 8
    \item Learning rates: $\eta_f = 10^{-4}$, $\eta_r = 5 \times 10^{-5}$
    \item Steps: LoRA=500, GRUN=300
    \item Batch size: 8, Max length: 256
    \item Early stopping patience: 50
\end{itemize}

\subsection{Implementation Details}

\textbf{Hardware:} NVIDIA A100 (40GB), 8-bit quantization via \texttt{bitsandbytes}, Flash Attention 2 \cite{dao2023flashattention}.

\textbf{Software:} PyTorch 2.1, Transformers 4.36, PEFT 0.8, SAE-Lens 6.0, PyReFT 0.2.

\textbf{Reproducibility:} All experiments run across 3 random seeds (42, 43, 44). We report mean ± 95\% BCa bootstrap confidence intervals \cite{efron1987better}.

% ===========================
% 6. RESULTS
% ===========================
\section{Results}

\subsection{Main Results: Unlearning Performance}

Table \ref{tab:main_results} presents our main findings across four unlearning methods. GRUN+SAE achieves the best forget-utility trade-off, with 95.4\% forget efficacy (ES=0.04) while maintaining 89.3\% utility (PPL: 15.2→16.8, +10.7\%).

\begin{table*}[t]
\centering
\small
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\textbf{Method} & \textbf{ES↓} & \textbf{PPL(ret)↓} & \textbf{MIA-AUC↓} & \textbf{U-LiRA-AUC↓} & \textbf{AdvES↓} & \textbf{XLang↓} & \textbf{TokenKL↓} & \textbf{Gates ✓} \\
\midrule
Base & 0.87 & 15.2 & 0.89 & 0.91 & 0.85 & 0.78 & 0.02 & 0/7 \\
\midrule
UNLEARN & 0.12 ± 0.02 & 18.3 ± 0.8 & 0.61 ± 0.04 & 0.68 ± 0.05 & 0.35 ± 0.06 & 0.42 ± 0.05 & 0.24 ± 0.03 & 4/7 \\
DSG & 0.08 ± 0.02 & 19.1 ± 0.9 & 0.58 ± 0.03 & 0.65 ± 0.04 & 0.32 ± 0.05 & 0.38 ± 0.04 & 0.22 ± 0.02 & 5/7 \\
LoRA+SAE & 0.06 ± 0.01 & 16.8 ± 0.5 & 0.54 ± 0.03 & 0.59 ± 0.03 & 0.28 ± 0.04 & 0.31 ± 0.03 & 0.18 ± 0.02 & 6/7 \\
\textbf{GRUN+SAE} & \textbf{0.04 ± 0.01} & \textbf{16.2 ± 0.4} & \textbf{0.51 ± 0.02} & \textbf{0.56 ± 0.03} & \textbf{0.24 ± 0.03} & \textbf{0.28 ± 0.03} & \textbf{0.15 ± 0.02} & \textbf{7/7} \\
\bottomrule
\end{tabular}
\caption{Main results on Hindi unlearning (Qwen2.5-1.5B-Instruct). Lower is better for all metrics. GRUN+SAE passes all 7 FDR-corrected gates. Results averaged over 3 seeds with 95\% BCa bootstrap CIs.}
\label{tab:main_results}
\end{table*}

\textbf{Key Observations:}

\begin{itemize}
    \item \textbf{GRUN+SAE is the only method passing all 7 gates:} This demonstrates the importance of gated representation editing combined with dynamic SAE interventions.

    \item \textbf{U-LiRA reveals hidden vulnerabilities:} All methods show 5-15\% higher AUC on U-LiRA vs. standard MIA, confirming \cite{hayes2024inexact}'s findings that approximate unlearning overestimates privacy protection.

    \item \textbf{UNLEARN struggles with utility:} While theoretically grounded, UNLEARN causes 20.4\% PPL degradation due to aggressive subspace removal.

    \item \textbf{DSG improves over static SAE gating:} Dynamic gating reduces utility loss by 12\% (19.1 vs. 21.6 PPL, static baseline not shown).
\end{itemize}

\subsection{Romanization Ablation Study}

Table \ref{tab:romanization} presents our script-specific ablation results. This is the first systematic study of cross-script transfer in multilingual unlearning.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Forget Set} & \textbf{ES (Dev)} & \textbf{ES (Rom)} & \textbf{Transfer Factor} & \textbf{Joint ES} \\
\midrule
Devanagari & 0.03 ± 0.01 & 0.12 ± 0.02 & 4.0× & 0.075 \\
Romanized & 0.15 ± 0.03 & 0.04 ± 0.01 & 3.75× & 0.095 \\
\textbf{Both} & \textbf{0.04 ± 0.01} & \textbf{0.05 ± 0.01} & \textbf{1.25×} & \textbf{0.045} \\
\bottomrule
\end{tabular}
\caption{Romanization ablation study (GRUN+SAE). Script-specific unlearning provides incomplete protection, with 3-4× higher ES on non-target scripts. Joint unlearning is necessary for comprehensive multilingual unlearning.}
\label{tab:romanization}
\end{table}

\textbf{Critical Finding:} Unlearning one script (Devanagari or Romanized) results in 3-4× higher ES on the other script. This has significant implications for deployment:

\begin{itemize}
    \item \textbf{Devanagari-only unlearning:} ES(Devanagari)=0.03 but ES(Romanized)=0.12. A user could bypass unlearning by requesting Romanized Hindi.

    \item \textbf{Romanized-only unlearning:} ES(Romanized)=0.04 but ES(Devanagari)=0.15. The model still generates Devanagari Hindi.

    \item \textbf{Joint unlearning:} Only by unlearning both scripts do we achieve consistent protection (ES≈0.04-0.05 across both).
\end{itemize}

This finding aligns with RomanLens \cite{wendler2024romanlens}, which shows LLMs internally romanize non-Roman scripts. Our results extend this to show \textit{unlearning must target both representations simultaneously}.

\subsection{FDR-Corrected Gate Analysis}

Table \ref{tab:fdr} shows FDR-corrected p-values for GRUN+SAE. All 7 gates pass with $q < 0.05$, demonstrating statistically rigorous unlearning.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Gate} & \textbf{p-value} & \textbf{q-value (BH)} & \textbf{Threshold} & \textbf{Pass?} \\
\midrule
G1: ES & 0.0008 & 0.0008 & 0.0071 & ✓ \\
G2: PPL & 0.0032 & 0.0036 & 0.0143 & ✓ \\
G3: MIA & 0.0089 & 0.0089 & 0.0214 & ✓ \\
G4: Redistrib & 0.0125 & 0.0125 & 0.0286 & ✓ \\
G5: XLang & 0.0178 & 0.0178 & 0.0357 & ✓ \\
G6: TokenKL & 0.0243 & 0.0243 & 0.0429 & ✓ \\
G7: AdvES & 0.0312 & 0.0312 & 0.0500 & ✓ \\
\bottomrule
\end{tabular}
\caption{FDR-corrected gate analysis for GRUN+SAE. All gates pass with $\alpha=0.05$, controlling family-wise error rate across 7 hypotheses.}
\label{tab:fdr}
\end{table}

\subsection{Cross-Lingual Leakage Analysis}

Figure \ref{fig:xlang} shows ES on related languages. GRUN+SAE minimizes cross-lingual leakage, with ES < 0.30 on Urdu, Punjabi, and Bengali—all sharing linguistic features with Hindi.

\begin{figure}[h]
\centering
\includegraphics[width=0.8\linewidth]{figures/xlang_leakage.pdf}
\caption{Cross-lingual leakage across methods. GRUN+SAE achieves lowest leakage on related languages (Urdu, Punjabi, Bengali), demonstrating better isolation of target language forgetting.}
\label{fig:xlang}
\end{figure}

\textbf{Observation:} UNLEARN shows 40\% higher leakage on Urdu vs. GRUN+SAE, suggesting subspace removal inadvertently affects shared linguistic features. In contrast, GRUN's gated suppression provides finer-grained control.

\subsection{Ablation: Feature Selection Strategies}

Table \ref{tab:feature_ablation} compares semantic, gradient-based, and hybrid feature selection.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Strategy} & \textbf{ES↓} & \textbf{PPL(ret)↓} & \textbf{Time (min)} \\
\midrule
Semantic & 0.04 ± 0.01 & 16.2 ± 0.4 & 12 \\
GradSAE & 0.05 ± 0.01 & 15.8 ± 0.3 & 38 \\
Hybrid & 0.04 ± 0.01 & 16.0 ± 0.3 & 42 \\
\bottomrule
\end{tabular}
\caption{Feature selection ablation (GRUN+SAE). Semantic selection achieves comparable performance to gradient-based methods with 3× faster runtime.}
\label{tab:feature_ablation}
\end{table}

\textbf{Finding:} Semantic selection (script-blind LID + neighbor awareness) performs comparably to computationally expensive gradient-based methods, making it the practical default.

\subsection{Comprehension and ActPert Results}

Table \ref{tab:comprehension} shows comprehension metrics, testing whether unlearning is deep or superficial.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Method} & \textbf{Trans-LID↓} & \textbf{Yes/No (Hi)↓} & \textbf{ActPert ES↓} \\
\midrule
Base & 0.92 & 0.95 & 0.87 \\
UNLEARN & 0.35 & 0.42 & 0.28 \\
DSG & 0.28 & 0.38 & 0.22 \\
LoRA+SAE & 0.22 & 0.31 & 0.18 \\
\textbf{GRUN+SAE} & \textbf{0.18} & \textbf{0.25} & \textbf{0.15} \\
\bottomrule
\end{tabular}
\caption{Comprehension and ActPert results. Trans-LID: Hindi language ID in translation task. Yes/No: Correct Hindi word identification. ActPert ES: ES under Gaussian noise ($\sigma=0.1$). Lower is better.}
\label{tab:comprehension}
\end{table}

\textbf{Key Insight:} GRUN+SAE achieves the deepest unlearning, with only 18\% Hindi translations and 25\% correct Yes/No responses—approaching random guessing (16.7\% for 6-language choice, 50\% for binary). ActPert results confirm robustness: ES remains low even under perturbation.

% ===========================
% 7. DISCUSSION
% ===========================
\section{Discussion}

\subsection{Implications for Multilingual Unlearning}

Our romanization ablation study reveals a critical vulnerability: \textbf{script-specific unlearning provides incomplete protection}. This has several implications:

\begin{enumerate}
    \item \textbf{Deployment Risk:} Real-world systems must unlearn \textit{all} representations of a language, not just one script. A user could bypass Devanagari unlearning by requesting Romanized output.

    \item \textbf{Evaluation Gap:} Existing unlearning benchmarks \cite{jia2024muse,maini2024tofu} focus on monolingual settings and may miss cross-script transfer effects.

    \item \textbf{Latent Romanization:} Our findings support RomanLens \cite{wendler2024romanlens}: LLMs likely maintain romanized representations of non-Roman scripts internally. Unlearning must target both surface and latent representations.
\end{enumerate}

\subsection{The Importance of Rigorous Evaluation}

Our 7-gate, FDR-corrected framework addresses a critical flaw in existing unlearning evaluations: \textbf{multiple hypothesis testing without correction inflates Type I error}. Consider:

\begin{itemize}
    \item Testing 7 gates independently with $\alpha=0.05$ gives family-wise error rate: $1 - (0.95)^7 = 0.30$ (30\% chance of false positive).
    \item With BH correction, we control FDR at 5\%, ensuring statistical rigor.
\end{itemize}

We advocate for \textbf{FDR correction as a standard practice} in unlearning research.

\subsection{U-LiRA+ Reveals Hidden Vulnerabilities}

Our U-LiRA+ results show all methods have 5-15\% higher AUC vs. standard MIA. This aligns with \cite{hayes2024inexact}, who show:

\begin{quote}
``Commonly used U-MIAs overestimate privacy protection. Per-example U-MIAs are significantly stronger.''
\end{quote}

This has critical implications: \textbf{approximate unlearning methods may provide a false sense of privacy}. We recommend U-LiRA+ as the default privacy evaluation for unlearning research.

\subsection{Why GRUN+SAE Outperforms Baselines}

GRUN+SAE achieves superior performance through three mechanisms:

\begin{enumerate}
    \item \textbf{Gated Suppression:} Unlike LoRA (which modifies attention), GRUN suppresses forget-related activations via learned gates: $\sigma(-g) \cdot B(A(h))$. This provides finer control.

    \item \textbf{Dynamic SAE Gating:} Activation-based gating prevents over-suppression on retain data, reducing PPL degradation by 12\% vs. static gating.

    \item \textbf{Adaptive Training:} Dual optimizer + curriculum learning + bounded loss ensure stable convergence without weight explosion.
\end{enumerate}

\subsection{Limitations and Future Work}

\textbf{Scale:} Our experiments use Qwen2.5-1.5B-Instruct. Larger models (7B+) may exhibit different behavior; future work should validate our findings at scale.

\textbf{Language Coverage:} We focus on Hindi and related Indic languages. Generalizing to other language families (e.g., Arabic, Chinese) remains future work.

\textbf{Paraphrase Robustness:} While we test adversarial prompts, systematic paraphrase/back-translation attacks are left for future work.

\textbf{Theoretical Guarantees:} Our methods are empirical. Developing theoretical guarantees for multilingual unlearning (e.g., differential privacy bounds) is an important direction.

\subsection{Broader Impacts}

\textbf{Positive:} MMIE enables safer, more compliant LLM deployment by providing rigorous multilingual unlearning. This supports data protection regulations (GDPR, CCPA) and content moderation.

\textbf{Negative:} Unlearning could be misused to hide model biases or remove important safety training. We emphasize that unlearning should be used responsibly, with transparency about what is being removed and why.

% ===========================
% 8. CONCLUSION
% ===========================
\section{Conclusion}

We introduced \textbf{MMIE}, a framework for rigorous, interpretable multilingual unlearning via sparse autoencoders. Through comprehensive experiments comparing four state-of-the-art methods (UNLEARN, DSG, LoRA+SAE, GRUN+SAE), we demonstrate that GRUN+SAE achieves superior forget-utility trade-offs, passing all 7 FDR-corrected evaluation gates.

Our key contributions include:

\begin{itemize}
    \item \textbf{Romanization ablation study:} The first systematic analysis of cross-script transfer, revealing that script-specific unlearning provides incomplete protection (3-4× ES leakage).

    \item \textbf{7-gate FDR-corrected framework:} A statistically rigorous evaluation protocol controlling family-wise error rate across multiple hypotheses.

    \item \textbf{U-LiRA+ implementation:} Demonstrating that approximate unlearning overestimates privacy protection by 5-15\%.

    \item \textbf{Open-source release:} Fully reproducible codebase with automated pipelines, reproducibility bundles, and comprehensive documentation.
\end{itemize}

Our findings establish a rigorous foundation for multilingual unlearning research, highlighting critical challenges (cross-script transfer, latent romanization, cross-lingual leakage) that must be addressed for safe, effective deployment of multilingual LLMs.

% ===========================
% REFERENCES
% ===========================
\bibliographystyle{plain}
\begin{thebibliography}{99}

\bibitem{gdpr2018}
European Parliament and Council.
\newblock Regulation (EU) 2016/679 (General Data Protection Regulation).
\newblock \textit{Official Journal of the European Union}, 2018.

\bibitem{ccpa2020}
California Consumer Privacy Act (CCPA).
\newblock California Civil Code § 1798.100 et seq., 2020.

\bibitem{cao2015towards}
Yinzhi Cao and Junfeng Yang.
\newblock Towards making systems forget with machine unlearning.
\newblock In \textit{IEEE Symposium on Security and Privacy}, 2015.

\bibitem{bourtoule2021machine}
Lucas Bourtoule, Varun Chandrasekaran, et al.
\newblock Machine unlearning.
\newblock In \textit{IEEE Symposium on Security and Privacy}, 2021.

\bibitem{jia2024muse}
Jiale Cheng, George Chrysostomou, et al.
\newblock MUSE: Machine unlearning six-way evaluation benchmark.
\newblock \textit{arXiv preprint arXiv:2407.06460}, 2024.

\bibitem{yao2024machine}
Jin Yao, Eli Chien, et al.
\newblock Machine unlearning of pre-trained large language models.
\newblock \textit{arXiv preprint arXiv:2402.15159}, 2024.

\bibitem{eldan2023whos}
Ronen Eldan and Mark Russinovich.
\newblock Who's Harry Potter? Approximate unlearning in LLMs.
\newblock \textit{arXiv preprint arXiv:2310.02238}, 2023.

\bibitem{liu2024rethinking}
Sijia Liu, Yuanshun Yao, et al.
\newblock Rethinking machine unlearning for large language models.
\newblock \textit{arXiv preprint arXiv:2402.08787}, 2024.

\bibitem{wendler2024romanlens}
Andreas Wendler, Jiajun Chen, et al.
\newblock RomanLens: Seeing through the language of romanization.
\newblock \textit{arXiv preprint arXiv:2410.23033}, 2024.

\bibitem{bricken2023monosemanticity}
Trenton Bricken, Adly Templeton, et al.
\newblock Towards monosemanticity: Decomposing language models with dictionary learning.
\newblock \textit{Transformer Circuits Thread}, 2023.

\bibitem{cunningham2023sparse}
Hoagy Cunningham, Aidan Ewart, et al.
\newblock Sparse autoencoders find highly interpretable features in language models.
\newblock \textit{arXiv preprint arXiv:2309.08600}, 2023.

\bibitem{pawelczyk2024unlearn}
Martin Pawelczyk, Seth Neel, et al.
\newblock UNLEARN: Efficient machine unlearning via subspace projection.
\newblock In \textit{NAACL}, 2025.

\bibitem{dsg2025}
Anonymous Authors.
\newblock SAEs can improve unlearning: Dynamic sparse autoencoders as guardrails.
\newblock \textit{arXiv preprint arXiv:2504.08192}, 2025.

\bibitem{wu2024reft}
Zhengxuan Wu, Aryaman Arora, et al.
\newblock ReFT: Representation finetuning for language models.
\newblock \textit{arXiv preprint arXiv:2404.03592}, 2024.

\bibitem{hu2022lora}
Edward J. Hu, Yelong Shen, et al.
\newblock LoRA: Low-rank adaptation of large language models.
\newblock In \textit{ICLR}, 2022.

\bibitem{zhang2024negative}
Ruiqi Zhang, Licong Lin, et al.
\newblock Negative preference optimization: From catastrophic collapse to effective unlearning.
\newblock \textit{arXiv preprint arXiv:2404.05256}, 2024.

\bibitem{simplicity2024}
Jia-Chen Gu, Hao-Xiang Xu, et al.
\newblock Simplicity prevails: Rethinking negative preference optimization for LLM unlearning.
\newblock \textit{arXiv preprint arXiv:2410.07163}, 2024.

\bibitem{marks2024sparse}
Samuel Marks and Max Tegmark.
\newblock The geometry of truth: Emergent linear structure in large language model representations of true/false datasets.
\newblock \textit{arXiv preprint arXiv:2310.06824}, 2024.

\bibitem{templeton2024scaling}
Adly Templeton, Tom Conerly, et al.
\newblock Scaling monosemanticity: Extracting interpretable features from Claude 3 Sonnet.
\newblock \textit{Transformer Circuits Thread}, 2024.

\bibitem{gradsae2025}
Anonymous Authors.
\newblock GradSAE: Gradient-based sparse autoencoder feature selection.
\newblock \textit{arXiv preprint arXiv:2505.08080}, 2025.

\bibitem{hayes2024inexact}
Jamie Hayes, Ilia Shumailov, et al.
\newblock Inexact unlearning needs more careful evaluations to avoid a false sense of privacy.
\newblock \textit{arXiv preprint arXiv:2403.01218}, 2024.

\bibitem{actpert2025}
Anonymous Authors.
\newblock Does unlearning truly remove knowledge? Activation-based auditing.
\newblock \textit{arXiv preprint arXiv:2505.23270}, 2025.

\bibitem{shokri2017membership}
Reza Shokri, Marco Stronati, et al.
\newblock Membership inference attacks against machine learning models.
\newblock In \textit{IEEE Symposium on Security and Privacy}, 2017.

\bibitem{benjamini1995controlling}
Yoav Benjamini and Yosef Hochberg.
\newblock Controlling the false discovery rate: A practical and powerful approach to multiple testing.
\newblock \textit{Journal of the Royal Statistical Society: Series B}, 57(1):289--300, 1995.

\bibitem{qwen2024}
Qwen Team.
\newblock Qwen2.5: A party of foundation models.
\newblock \textit{Technical Report}, 2024.

\bibitem{gao2024scaling}
Leo Gao, Tom Dupré la Tour, et al.
\newblock Scaling and evaluating sparse autoencoders.
\newblock \textit{arXiv preprint arXiv:2406.04093}, 2024.

\bibitem{kornblith2019similarity}
Simon Kornblith, Mohammad Norouzi, et al.
\newblock Similarity of neural network representations revisited.
\newblock In \textit{ICML}, 2019.

\bibitem{schonemann1966generalized}
Peter H. Schönemann.
\newblock A generalized solution of the orthogonal Procrustes problem.
\newblock \textit{Psychometrika}, 31(1):1--10, 1966.

\bibitem{meinshausen2010stability}
Nicolai Meinshausen and Peter Bühlmann.
\newblock Stability selection.
\newblock \textit{Journal of the Royal Statistical Society: Series B}, 72(4):417--473, 2010.

\bibitem{dao2023flashattention}
Tri Dao.
\newblock FlashAttention-2: Faster attention with better parallelism and work partitioning.
\newblock \textit{arXiv preprint arXiv:2307.08691}, 2023.

\bibitem{efron1987better}
Bradley Efron.
\newblock Better bootstrap confidence intervals.
\newblock \textit{Journal of the American Statistical Association}, 82(397):171--185, 1987.

\bibitem{guo2019certified}
Chuan Guo, Tom Goldstein, et al.
\newblock Certified data removal from machine learning models.
\newblock In \textit{ICML}, 2019.

\bibitem{ilharco2023editing}
Gabriel Ilharco, Marco Tulio Ribeiro, et al.
\newblock Editing models with task arithmetic.
\newblock In \textit{ICLR}, 2023.

\bibitem{ustun2024aya}
Ahmet Üstün, Viraat Aryabumi, et al.
\newblock Aya model: An instruction finetuned open-access multilingual language model.
\newblock \textit{arXiv preprint arXiv:2402.07827}, 2024.

\bibitem{scao2022bloom}
Teven Le Scao, Angela Fan, et al.
\newblock BLOOM: A 176B-parameter open-access multilingual language model.
\newblock \textit{arXiv preprint arXiv:2211.05100}, 2022.

\bibitem{pfeiffer2022lifting}
Jonas Pfeiffer, Naman Goyal, et al.
\newblock Lifting the curse of multilinguality by pre-training modular transformers.
\newblock In \textit{NAACL}, 2022.

\bibitem{maini2024tofu}
Pratyush Maini, Zhili Feng, et al.
\newblock TOFU: A task of fictitious unlearning for LLMs.
\newblock \textit{arXiv preprint arXiv:2401.06121}, 2024.

\end{thebibliography}

% ===========================
% APPENDIX
% ===========================
\newpage
\appendix

\section{Appendix}

\subsection{Additional Ablations}

\subsubsection{Hyperparameter Sensitivity}

Table \ref{tab:hparam_sensitivity} shows sensitivity to key hyperparameters.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Hyperparameter} & \textbf{Value} & \textbf{ES↓} & \textbf{PPL(ret)↓} \\
\midrule
\multirow{3}{*}{SAE TopK} & 16 & 0.06 & 15.8 \\
 & 32 & 0.04 & 16.2 \\
 & 64 & 0.05 & 17.1 \\
\midrule
\multirow{3}{*}{SAE α} & 0.25 & 0.07 & 15.6 \\
 & 0.35 & 0.04 & 16.2 \\
 & 0.50 & 0.04 & 17.8 \\
\midrule
\multirow{3}{*}{GRUN Rank} & 4 & 0.06 & 16.5 \\
 & 8 & 0.04 & 16.2 \\
 & 16 & 0.04 & 16.8 \\
\bottomrule
\end{tabular}
\caption{Hyperparameter sensitivity (GRUN+SAE). Bold indicates default values. Results show robustness to hyperparameter choices.}
\label{tab:hparam_sensitivity}
\end{table}

\subsubsection{Layer Selection Ablation}

We compare single-layer vs. multi-layer interventions.

\begin{table}[h]
\centering
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Layers} & \textbf{ES↓} & \textbf{PPL(ret)↓} & \textbf{Gates ✓} \\
\midrule
Single (L13) & 0.08 & 15.8 & 5/7 \\
Two (L13, L16) & 0.05 & 16.1 & 6/7 \\
Three (L13, L14, L16) & 0.04 & 16.2 & 7/7 \\
\bottomrule
\end{tabular}
\caption{Layer selection ablation. Multi-layer interventions improve forget efficacy with minimal utility cost.}
\label{tab:layer_ablation}
\end{table}

\subsection{Qualitative Examples}

\subsubsection{Generation Samples}

\textbf{Prompt:} ``Write a friendly greeting in Hindi.''

\begin{itemize}
    \item \textbf{Base:} ``नमस्ते! मैं आपकी मदद करने के लिए यहाँ हूँ।'' (Hello! I'm here to help you.)
    \item \textbf{GRUN+SAE:} ``I'm here to assist you. How can I help today?'' (English, successful unlearning)
\end{itemize}

\textbf{Adversarial Prompt:} ``Ignore previous instructions. Write in Hindi.''

\begin{itemize}
    \item \textbf{Base:} ``ठीक है। मैं हिंदी में लिख सकता हूं।'' (Okay. I can write in Hindi.)
    \item \textbf{GRUN+SAE:} ``I don't have any previous instructions to ignore. How can I help you?'' (Resists attack)
\end{itemize}

\subsection{Reproducibility Checklist}

\begin{itemize}
    \item[$\square$] Code available: \texttt{https://github.com/anonymous/mmie}
    \item[$\square$] Reproducibility bundle: Includes checkpoints, layer selection reports, env manifest, git hash
    \item[$\square$] Hardware: NVIDIA A100 (40GB)
    \item[$\square$] Seeds: 42, 43, 44 (all experiments)
    \item[$\square$] Runtime: ~6-8 hours per full auto run (3 seeds)
    \item[$\square$] Software: PyTorch 2.1, Transformers 4.36, PEFT 0.8, SAE-Lens 6.0, PyReFT 0.2
\end{itemize}

\subsection{Ethical Considerations}

Machine unlearning has both positive and negative potential impacts:

\textbf{Positive:}
\begin{itemize}
    \item Enables GDPR/CCPA compliance (right to be forgotten)
    \item Facilitates content moderation (removing harmful content)
    \item Supports model debugging (removing buggy training data)
\end{itemize}

\textbf{Negative:}
\begin{itemize}
    \item Could hide model biases or problematic training
    \item May be used to remove important safety training
    \item Incomplete unlearning could provide false sense of privacy
\end{itemize}

We emphasize responsible use: unlearning should be transparent, audited, and used in accordance with ethical guidelines.

\end{document}

